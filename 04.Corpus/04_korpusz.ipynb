{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. óra\n",
    "## Korpuszépítés\n",
    "\n",
    "### Crawling és scraping \n",
    "\n",
    "\n",
    "| crawling | scraping |\n",
    "|:- | :- |\n",
    "| weboldalak letöltése keresőrobotokkal | adatkinyerés (sokféle adatból történhet) | \n",
    "| nagy mennyiségű adatot nyerünk ki általában   | bármilyen méretet ölthet  |\n",
    "| (általában) minden adat kinyerése | specifikus adat kinyerése  |\n",
    "| gyakran rekuzív, azaz a kezdőoldalon található linkeket \"követi\" |nem feltétlenül rekurzív, gyakran csak egy oldal a tárgya |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Weboldalak letöltése Pythonnal\n",
    "\n",
    "- urllib csomag használata\n",
    "- weboldal fájlba mentése"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "urllib.request.urlretrieve('http://python.org/', 'website.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BeautifulSoup\n",
    "\n",
    "A BeautifulSoup egy HTML és XML fájlok elemzésére, átalakítására szolgáló python csomag, amellyel scrapingelni tudunk HTML fájlokat, sztringeket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# stringből\n",
    "\n",
    "html = '''\n",
    "<html>\n",
    "    <head>\n",
    "        <title>BeautifulSoup példa</title>\n",
    "    </head>\n",
    "    <body>\n",
    "        <h1>Korpuszépítés</h1>\n",
    "        <p>Lórum <a class=\"word\">ipse</a> nem kodik, ha kodik, már nem siánság többé. \n",
    "        Illírnek lengi hangás a botós és a nyalmas burniák \n",
    "        vencshez <a href=\"#valo\">való</a> lászovátomát az \n",
    "        <a class=\"word\">állott</a> gyávatokban? </p>\n",
    "        <ul>\n",
    "            <li>Listaelem 1</li>\n",
    "            <li>Listaelem 2</li>\n",
    "            <li>Listaelem 3</li>\n",
    "        </ul>\n",
    "    </body>\n",
    "</html>\n",
    "'''\n",
    "\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "print(type(soup), '\\n\\n')   # a leves típusa\n",
    "print(soup.prettify())      # tagek rendezése, formázás"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fájlból\n",
    "\n",
    "soup_file = BeautifulSoup(open('website.html', encoding='utf-8'), 'html.parser')\n",
    "print(soup_file.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tagek\n",
    "\n",
    "links = soup.find_all('a')  # .find_all() kigyűjti az oldalról az összes paraméterként átadott taget\n",
    "for link in links[:10]:\n",
    "    print(link.get('href')) # .get() egy attribútum értékét adja vissza\n",
    "    \n",
    "links = soup.find_all('a', 'word')  # csak a \"word\" értékkel rendelkező a tagek kigyűjtése \n",
    "for link in links:\n",
    "    print(link.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# szöveg\n",
    "\n",
    "print(links[4])\n",
    "print()\n",
    "print(links[4].get_text())  # .get_text() kinyeri az adott tagen belüli (összes) szöveget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feladatok\n",
    "\n",
    "1. Töltsük le a https://www.imdb.com/chart/tvmeter/?ref_=nv_tvv_mptv oldalt, és mentsük el .html fájlként.\n",
    "\n",
    "2. BeautifulSoup-ot használva mentsük egy listába az oldalról az olyan _&lt;td>_ tageket, amelyek _class_ attribútuma _titleColumn_.\n",
    "\n",
    "3. Írjuk ki az _&lt;a>_ tagen belül található szövegeket."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Irodalom\n",
    "\n",
    "- [urllib](https://docs.python.org/3/library/urllib.html)\n",
    "- [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
